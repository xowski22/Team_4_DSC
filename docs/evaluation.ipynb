{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metric: MAP@10 (Mean Average Precision at 10)\n",
    "\n",
    "This notebook explains the evaluation metric used in our Kaggle competition - **MAP@10** (Mean Average Precision at 10).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üéØ What is MAP@10?\n",
    "\n",
    "**MAP@10** is a ranking evaluation metric that measures how well our recommendation system performs by looking at the **top 10 recommendations** for each user.\n",
    "\n",
    "### Key Formula:\n",
    "```\n",
    "MAP@10 = (1/|U|) √ó Œ£(u‚ààU) AP@10(u)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- **U** = Set of all users\n",
    "- **AP@10(u)** = Average Precision at 10 for user u\n",
    "- We take the **average** across all users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üìä Breaking Down AP@10 (Average Precision at 10)\n",
    "\n",
    "For each individual user **u**, we calculate:\n",
    "\n",
    "```\n",
    "AP@10(u) = (1/min(|R_u|, 10)) √ó Œ£(k=1 to 10) P_u(k) √ó rel_u(k)\n",
    "```\n",
    "\n",
    "### Components:\n",
    "- **R_u** = Set of relevant (true) items for user u\n",
    "- **P_u(k)** = Precision at position k = (# of relevant items in top k) / k\n",
    "- **rel_u(k)** = 1 if item at position k is relevant, 0 otherwise\n",
    "\n",
    "### üîç What this means:\n",
    "- We only look at the **first 10 recommendations**\n",
    "- We calculate precision at each position (1st, 2nd, 3rd, ... 10th)\n",
    "- We only count positions where we made a **correct recommendation**\n",
    "- We normalize by the number of possible relevant items (max 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üí° Simple Example\n",
    "\n",
    "Let's say we have a user with **3 relevant items** in total, and our system makes these top-10 recommendations:\n",
    "\n",
    "| Position (k) | Recommended Item | Relevant? | rel_u(k) | Precision P_u(k) |\n",
    "|--------------|------------------|-----------|----------|------------------|\n",
    "| 1            | Item A           | ‚úÖ Yes    | 1        | 1/1 = 1.00       |\n",
    "| 2            | Item B           | ‚ùå No     | 0        | 1/2 = 0.50       |\n",
    "| 3            | Item C           | ‚úÖ Yes    | 1        | 2/3 = 0.67       |\n",
    "| 4            | Item D           | ‚ùå No     | 0        | 2/4 = 0.50       |\n",
    "| 5            | Item E           | ‚úÖ Yes    | 1        | 3/5 = 0.60       |\n",
    "| 6-10         | Items F-J        | ‚ùå No     | 0        | ...              |\n",
    "\n",
    "### Calculation:\n",
    "```\n",
    "AP@10 = (1/min(3,10)) √ó [1√ó1.00 + 0√ó0.50 + 1√ó0.67 + 0√ó0.50 + 1√ó0.60 + 0√ó...]\n",
    "AP@10 = (1/3) √ó [1.00 + 0.67 + 0.60]\n",
    "AP@10 = (1/3) √ó 2.27 = 0.757\n",
    "```\n",
    "\n",
    "**This user gets an AP@10 score of 0.757**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üé™ Visual Representation\n",
    "\n",
    "Let's create a simple visualization to understand how MAP@10 works:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example recommendation scenario\n",
    "positions = np.arange(1, 11)\n",
    "recommendations = ['Item A', 'Item B', 'Item C', 'Item D', 'Item E', \n",
    "                  'Item F', 'Item G', 'Item H', 'Item I', 'Item J']\n",
    "relevant = [1, 0, 1, 0, 1, 0, 0, 0, 0, 0]  # 1 = relevant, 0 = not relevant\n",
    "colors = ['green' if r else 'red' for r in relevant]\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Top plot: Recommendations with relevance\n",
    "bars1 = ax1.bar(positions, [1]*10, color=colors, alpha=0.7)\n",
    "ax1.set_xlabel('Recommendation Position')\n",
    "ax1.set_ylabel('Recommendations')\n",
    "ax1.set_title('Top-10 Recommendations (Green = Relevant, Red = Not Relevant)')\n",
    "ax1.set_xticks(positions)\n",
    "ax1.set_ylim(0, 1.2)\n",
    "\n",
    "# Add item labels\n",
    "for i, (pos, item) in enumerate(zip(positions, recommendations)):\n",
    "    ax1.text(pos, 0.5, item, ha='center', va='center', fontweight='bold')\n",
    "\n",
    "# Bottom plot: Cumulative precision\n",
    "cumulative_hits = np.cumsum(relevant)\n",
    "precision_at_k = cumulative_hits / positions\n",
    "weighted_precision = [p * r for p, r in zip(precision_at_k, relevant)]\n",
    "\n",
    "ax2.plot(positions, precision_at_k, 'bo-', linewidth=2, markersize=6, label='Precision@k')\n",
    "ax2.bar(positions, weighted_precision, alpha=0.5, color='orange', \n",
    "        label='Weighted Precision (only counted when relevant)')\n",
    "ax2.set_xlabel('Position k')\n",
    "ax2.set_ylabel('Precision Value')\n",
    "ax2.set_title('Precision@k and Weighted Precision for MAP@10 Calculation')\n",
    "ax2.set_xticks(positions)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display the final AP@10\n",
    "relevant_items_count = sum(relevant)\n",
    "ap_10 = sum(weighted_precision) / min(relevant_items_count, 10)\n",
    "print(f\"\\nüìä Calculation Results:\")\n",
    "print(f\"Number of relevant items found: {relevant_items_count}\")\n",
    "print(f\"Sum of weighted precisions: {sum(weighted_precision):.3f}\")\n",
    "print(f\"AP@10 for this user: {ap_10:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üîë Key Insights\n",
    "\n",
    "### Why MAP@10 is Important:\n",
    "\n",
    "1. **üéØ Position Matters**: Earlier relevant recommendations contribute more to the score\n",
    "2. **‚öñÔ∏è Balanced Metric**: Considers both precision and the ranking order\n",
    "3. **üìè Standardized**: Scores range from 0 to 1, making comparison easy\n",
    "4. **üë• User-Centric**: Calculated per user, then averaged across all users\n",
    "\n",
    "### What Makes a Good MAP@10 Score:\n",
    "\n",
    "- **Perfect Score (1.0)**: All relevant items appear at the very beginning of recommendations\n",
    "- **Good Score (0.7-0.9)**: Most relevant items appear in early positions\n",
    "- **Poor Score (0.0-0.3)**: Few relevant items found, or they appear late in the ranking\n",
    "\n",
    "### üìà To Improve MAP@10:\n",
    "- Focus on getting relevant items **higher in the ranking**\n",
    "- Improve the **quality** of top recommendations\n",
    "- Balance between **precision** and **recall** in your recommendation system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üèÜ Summary\n",
    "\n",
    "**MAP@10** is the evaluation metric for this competition. It measures how well our recommendation system ranks relevant items within the top 10 positions.\n",
    "\n",
    "### The Final Formula:\n",
    "```\n",
    "MAP@10 = Average of AP@10 scores across all users\n",
    "```\n",
    "\n",
    "Where each user's AP@10 considers:\n",
    "- ‚úÖ **Which** of our top-10 recommendations are correct\n",
    "- üìç **Where** these correct recommendations appear in the ranking\n",
    "- üéØ **How many** relevant items the user actually has\n",
    "\n",
    "### üí° Remember:\n",
    "- **Higher is better** (max score = 1.0)\n",
    "- **Position matters** - relevant items should appear early\n",
    "- **Every user counts** - we average across all users in the dataset\n",
    "\n",
    "This metric ensures we build recommendation systems that are both **accurate** and **well-ordered**! üöÄ\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
