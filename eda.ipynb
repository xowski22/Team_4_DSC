{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "## Team 4 - Data Science Club  \n",
    "**Product Recommendation Challenge**\n",
    "\n",
    "This notebook contains comprehensive exploratory data analysis of the Kaggle Product Recommendation Challenge dataset.\n",
    "\n",
    "**Dataset Structure:**\n",
    "- `train.csv`: User-item interactions with ratings and timestamps\n",
    "- `test.csv`: Users for whom we need to make predictions  \n",
    "- `item_metadata.csv`: Product information including categories, prices, descriptions\n",
    "- `id_mappings.json`: Mappings between original IDs and encoded numeric IDs\n",
    "- `sample_submission.csv`: Expected submission format (top 10 item recommendations per user)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Import Libraries and Setup](#1-import-libraries-and-setup)\n",
    "2. [Data Loading and Overview](#2-data-loading-and-overview)\n",
    "3. [Data Quality Assessment](#3-data-quality-assessment)\n",
    "4. [Training Data Analysis](#4-training-data-analysis)\n",
    "   - User-Item Interaction Patterns\n",
    "   - Rating Distribution Analysis\n",
    "   - Temporal Analysis (Timestamps)\n",
    "   - User Behavior Analysis\n",
    "   - Item Popularity Analysis\n",
    "5. [Item Metadata Analysis](#5-item-metadata-analysis)\n",
    "   - Product Categories Distribution\n",
    "   - Price Analysis\n",
    "   - Rating Analysis\n",
    "   - Feature Analysis\n",
    "6. [ID Mappings Analysis](#6-id-mappings-analysis)\n",
    "7. [Data Relationships and Correlations](#7-data-relationships-and-correlations)\n",
    "8. [Cold Start Problem Analysis](#8-cold-start-problem-analysis)\n",
    "9. [Sparsity Analysis](#9-sparsity-analysis)\n",
    "10. [Test Set Analysis](#10-test-set-analysis)\n",
    "11. [Key Insights and Recommendations](#11-key-insights-and-recommendations)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Import Libraries and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Machine learning utilities\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Data Loading and Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Training data - user-item interactions with ratings and timestamps\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "print(f\"✓ Training data loaded: {train_df.shape}\")\n",
    "\n",
    "# Test data - users for whom we need to make predictions\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "print(f\"✓ Test data loaded: {test_df.shape}\")\n",
    "\n",
    "# Sample submission - expected format (user_id: space-separated item recommendations)\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "print(f\"✓ Sample submission loaded: {sample_submission.shape}\")\n",
    "\n",
    "# Item metadata - product information\n",
    "item_metadata = pd.read_csv('data/item_metadata.csv')\n",
    "print(f\"✓ Item metadata loaded: {item_metadata.shape}\")\n",
    "\n",
    "# ID mappings - mappings between original IDs and encoded numeric IDs\n",
    "with open('data/id_mappings.json', 'r') as f:\n",
    "    id_mappings = json.load(f)\n",
    "print(f\"✓ ID mappings loaded\")\n",
    "\n",
    "print(\"\\nAll datasets loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset overview\n",
    "datasets = {\n",
    "    'Training Data': train_df,\n",
    "    'Test Data': test_df,\n",
    "    'Sample Submission': sample_submission,\n",
    "    'Item Metadata': item_metadata\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "\n",
    "print(f\"\\nID Mappings structure:\")\n",
    "for key in id_mappings.keys():\n",
    "    if isinstance(id_mappings[key], dict):\n",
    "        print(f\"  {key}: {len(id_mappings[key])} mappings\")\n",
    "    else:\n",
    "        print(f\"  {key}: {type(id_mappings[key])}\")\n",
    "\n",
    "# Display first few rows of each dataset\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{name.upper()} - First 5 rows:\")\n",
    "    print(\"-\" * 40)\n",
    "    display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MISSING VALUES ANALYSIS\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMISSING VALUES ANALYSIS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, df \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdatasets\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     23\u001b[0m     analyze_missing_values(df, name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# Missing values analysis\n",
    "def analyze_missing_values(df, name):\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(\"-\" * 30)\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    \n",
    "    if missing.sum() == 0:\n",
    "        print(\"✓ No missing values found!\")\n",
    "    else:\n",
    "        missing_df = pd.DataFrame({\n",
    "            'Missing Count': missing,\n",
    "            'Missing Percentage': missing_pct.round(2)\n",
    "        }).sort_values('Missing Count', ascending=False)\n",
    "        \n",
    "        display(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    analyze_missing_values(df, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"DUPLICATE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"{name}: {duplicates} duplicate rows ({duplicates/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Data types analysis\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA TYPES ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Data types: {df.dtypes.value_counts().to_dict()}\")\n",
    "    \n",
    "    # Identify potential issues\n",
    "    object_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(object_cols) > 0:\n",
    "        print(f\"  Text columns: {list(object_cols)}\")\n",
    "        \n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"  Numeric columns: {list(numeric_cols)}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Training Data Analysis\n",
    "\n",
    "### 4.1 User-Item Interaction Patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics about training data\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING DATA BASIC STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Number of unique users: {train_df['user_id'].nunique():,}\")\n",
    "print(f\"Number of unique items: {train_df['item_id'].nunique():,}\")\n",
    "print(f\"Number of interactions: {len(train_df):,}\")\n",
    "print(f\"Date range: {pd.to_datetime(train_df['timestamp'], unit='ms').min()} to {pd.to_datetime(train_df['timestamp'], unit='ms').max()}\")\n",
    "\n",
    "# Statistical summary\n",
    "print(f\"\\nStatistical summary:\")\n",
    "display(train_df.describe())\n",
    "\n",
    "# Rating distribution\n",
    "print(f\"\\nRating distribution:\")\n",
    "display(train_df['rating'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize rating distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Rating distribution histogram\n",
    "train_df['rating'].hist(bins=20, ax=axes[0], alpha=0.7)\n",
    "axes[0].set_title('Rating Distribution')\n",
    "axes[0].set_xlabel('Rating')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Rating distribution pie chart\n",
    "rating_counts = train_df['rating'].value_counts().sort_index()\n",
    "axes[1].pie(rating_counts.values, labels=rating_counts.index, autopct='%1.1f%%')\n",
    "axes[1].set_title('Rating Distribution (Percentage)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Rating statistics\n",
    "print(\"Rating Statistics:\")\n",
    "print(f\"Mean rating: {train_df['rating'].mean():.2f}\")\n",
    "print(f\"Median rating: {train_df['rating'].median():.2f}\")\n",
    "print(f\"Mode rating: {train_df['rating'].mode().iloc[0]:.1f}\")\n",
    "print(f\"Standard deviation: {train_df['rating'].std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 4.2 User Behavior Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User activity analysis\n",
    "user_stats = train_df.groupby('user_id').agg({\n",
    "    'item_id': 'count',\n",
    "    'rating': ['mean', 'std', 'min', 'max']\n",
    "}).round(2)\n",
    "\n",
    "user_stats.columns = ['num_interactions', 'avg_rating', 'rating_std', 'min_rating', 'max_rating']\n",
    "user_stats = user_stats.reset_index()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"USER BEHAVIOR ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"User interaction statistics:\")\n",
    "display(user_stats.describe())\n",
    "\n",
    "# Visualize user activity distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Number of interactions per user\n",
    "axes[0,0].hist(user_stats['num_interactions'], bins=50, alpha=0.7)\n",
    "axes[0,0].set_title('Distribution of User Interactions')\n",
    "axes[0,0].set_xlabel('Number of Interactions')\n",
    "axes[0,0].set_ylabel('Number of Users')\n",
    "axes[0,0].set_yscale('log')\n",
    "\n",
    "# Average rating per user\n",
    "axes[0,1].hist(user_stats['avg_rating'], bins=30, alpha=0.7)\n",
    "axes[0,1].set_title('Distribution of Average User Ratings')\n",
    "axes[0,1].set_xlabel('Average Rating')\n",
    "axes[0,1].set_ylabel('Number of Users')\n",
    "\n",
    "# Rating standard deviation per user\n",
    "axes[1,0].hist(user_stats['rating_std'].dropna(), bins=30, alpha=0.7)\n",
    "axes[1,0].set_title('Distribution of User Rating Standard Deviation')\n",
    "axes[1,0].set_xlabel('Rating Std Dev')\n",
    "axes[1,0].set_ylabel('Number of Users')\n",
    "\n",
    "# Rating range per user\n",
    "user_stats['rating_range'] = user_stats['max_rating'] - user_stats['min_rating']\n",
    "axes[1,1].hist(user_stats['rating_range'], bins=20, alpha=0.7)\n",
    "axes[1,1].set_title('Distribution of User Rating Range')\n",
    "axes[1,1].set_xlabel('Rating Range')\n",
    "axes[1,1].set_ylabel('Number of Users')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 4.3 Item Popularity Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item popularity analysis\n",
    "item_stats = train_df.groupby('item_id').agg({\n",
    "    'user_id': 'count',\n",
    "    'rating': ['mean', 'std', 'min', 'max']\n",
    "}).round(2)\n",
    "\n",
    "item_stats.columns = ['num_interactions', 'avg_rating', 'rating_std', 'min_rating', 'max_rating']\n",
    "item_stats = item_stats.reset_index()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ITEM POPULARITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Item interaction statistics:\")\n",
    "display(item_stats.describe())\n",
    "\n",
    "# Most popular items\n",
    "print(\"\\nTop 10 most popular items (by number of interactions):\")\n",
    "top_items = item_stats.nlargest(10, 'num_interactions')\n",
    "display(top_items)\n",
    "\n",
    "# Highest rated items (with minimum interactions)\n",
    "min_interactions = 10\n",
    "highly_rated = item_stats[item_stats['num_interactions'] >= min_interactions].nlargest(10, 'avg_rating')\n",
    "print(f\"\\nTop 10 highest rated items (min {min_interactions} interactions):\")\n",
    "display(highly_rated)\n",
    "\n",
    "# Visualize item popularity\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Item interaction distribution\n",
    "axes[0,0].hist(item_stats['num_interactions'], bins=50, alpha=0.7)\n",
    "axes[0,0].set_title('Distribution of Item Interactions')\n",
    "axes[0,0].set_xlabel('Number of Interactions')\n",
    "axes[0,0].set_ylabel('Number of Items')\n",
    "axes[0,0].set_yscale('log')\n",
    "\n",
    "# Item average rating distribution\n",
    "axes[0,1].hist(item_stats['avg_rating'], bins=30, alpha=0.7)\n",
    "axes[0,1].set_title('Distribution of Item Average Ratings')\n",
    "axes[0,1].set_xlabel('Average Rating')\n",
    "axes[0,1].set_ylabel('Number of Items')\n",
    "\n",
    "# Scatter plot: popularity vs rating\n",
    "axes[1,0].scatter(item_stats['num_interactions'], item_stats['avg_rating'], alpha=0.5)\n",
    "axes[1,0].set_title('Item Popularity vs Average Rating')\n",
    "axes[1,0].set_xlabel('Number of Interactions')\n",
    "axes[1,0].set_ylabel('Average Rating')\n",
    "axes[1,0].set_xscale('log')\n",
    "\n",
    "# Long tail analysis\n",
    "item_counts = item_stats['num_interactions'].sort_values(ascending=False)\n",
    "axes[1,1].plot(range(len(item_counts)), item_counts.values)\n",
    "axes[1,1].set_title('Long Tail Distribution of Item Popularity')\n",
    "axes[1,1].set_xlabel('Item Rank')\n",
    "axes[1,1].set_ylabel('Number of Interactions')\n",
    "axes[1,1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 4.4 Temporal Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime\n",
    "train_df['datetime'] = pd.to_datetime(train_df['timestamp'], unit='ms')\n",
    "train_df['date'] = train_df['datetime'].dt.date\n",
    "train_df['year'] = train_df['datetime'].dt.year\n",
    "train_df['month'] = train_df['datetime'].dt.month\n",
    "train_df['day_of_week'] = train_df['datetime'].dt.day_name()\n",
    "train_df['hour'] = train_df['datetime'].dt.hour\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEMPORAL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Interactions over time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Interactions by year\n",
    "yearly_counts = train_df['year'].value_counts().sort_index()\n",
    "axes[0,0].bar(yearly_counts.index, yearly_counts.values)\n",
    "axes[0,0].set_title('Interactions by Year')\n",
    "axes[0,0].set_xlabel('Year')\n",
    "axes[0,0].set_ylabel('Number of Interactions')\n",
    "\n",
    "# Interactions by month\n",
    "monthly_counts = train_df['month'].value_counts().sort_index()\n",
    "axes[0,1].bar(monthly_counts.index, monthly_counts.values)\n",
    "axes[0,1].set_title('Interactions by Month')\n",
    "axes[0,1].set_xlabel('Month')\n",
    "axes[0,1].set_ylabel('Number of Interactions')\n",
    "\n",
    "# Interactions by day of week\n",
    "dow_counts = train_df['day_of_week'].value_counts()\n",
    "dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_counts = dow_counts.reindex(dow_order)\n",
    "axes[1,0].bar(range(len(dow_counts)), dow_counts.values)\n",
    "axes[1,0].set_title('Interactions by Day of Week')\n",
    "axes[1,0].set_xlabel('Day of Week')\n",
    "axes[1,0].set_ylabel('Number of Interactions')\n",
    "axes[1,0].set_xticks(range(len(dow_counts)))\n",
    "axes[1,0].set_xticklabels(dow_counts.index, rotation=45)\n",
    "\n",
    "# Interactions by hour\n",
    "hourly_counts = train_df['hour'].value_counts().sort_index()\n",
    "axes[1,1].bar(hourly_counts.index, hourly_counts.values)\n",
    "axes[1,1].set_title('Interactions by Hour of Day')\n",
    "axes[1,1].set_xlabel('Hour')\n",
    "axes[1,1].set_ylabel('Number of Interactions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Time series plot\n",
    "daily_interactions = train_df.groupby('date').size()\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(daily_interactions.index, daily_interactions.values)\n",
    "plt.title('Daily Interactions Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Interactions')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Item Metadata Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item metadata overview\n",
    "print(\"=\" * 60)\n",
    "print(\"ITEM METADATA ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Item metadata shape: {item_metadata.shape}\")\n",
    "print(f\"Columns: {list(item_metadata.columns)}\")\n",
    "\n",
    "# Display basic info about metadata\n",
    "print(\"\\nMetadata column statistics:\")\n",
    "for col in item_metadata.columns:\n",
    "    print(f\"{col}: {item_metadata[col].dtype} - {item_metadata[col].nunique()} unique values\")\n",
    "\n",
    "# Category analysis\n",
    "print(\"\\nTop 10 main categories:\")\n",
    "if 'main_category' in item_metadata.columns:\n",
    "    category_counts = item_metadata['main_category'].value_counts().head(10)\n",
    "    display(category_counts)\n",
    "    \n",
    "    # Visualize categories\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    category_counts.plot(kind='bar')\n",
    "    plt.title('Top 10 Product Categories')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Number of Products')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Price analysis\n",
    "if 'price' in item_metadata.columns:\n",
    "    print(\"\\nPrice analysis:\")\n",
    "    # Convert price to numeric (handle 'None' values)\n",
    "    item_metadata['price_numeric'] = pd.to_numeric(item_metadata['price'], errors='coerce')\n",
    "    price_stats = item_metadata['price_numeric'].describe()\n",
    "    print(price_stats)\n",
    "    \n",
    "    # Price distribution\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    item_metadata['price_numeric'].dropna().hist(bins=50, alpha=0.7)\n",
    "    plt.title('Price Distribution')\n",
    "    plt.xlabel('Price')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    item_metadata['price_numeric'].dropna().plot(kind='box')\n",
    "    plt.title('Price Box Plot')\n",
    "    plt.ylabel('Price')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Rating analysis in metadata\n",
    "if 'average_rating' in item_metadata.columns:\n",
    "    print(\"\\nMetadata rating analysis:\")\n",
    "    rating_stats = item_metadata['average_rating'].describe()\n",
    "    print(rating_stats)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    item_metadata['average_rating'].hist(bins=30, alpha=0.7)\n",
    "    plt.title('Average Rating Distribution (Metadata)')\n",
    "    plt.xlabel('Average Rating')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    if 'rating_number' in item_metadata.columns:\n",
    "        plt.scatter(item_metadata['rating_number'], item_metadata['average_rating'], alpha=0.5)\n",
    "        plt.title('Number of Ratings vs Average Rating')\n",
    "        plt.xlabel('Number of Ratings')\n",
    "        plt.ylabel('Average Rating')\n",
    "        plt.xscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. ID Mappings Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID mappings analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"ID MAPPINGS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analyze mapping structure\n",
    "for key, value in id_mappings.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"\\n{key}:\")\n",
    "        print(f\"  Number of mappings: {len(value)}\")\n",
    "        if len(value) > 0:\n",
    "            # Show sample mappings\n",
    "            sample_keys = list(value.keys())[:5]\n",
    "            print(f\"  Sample mappings:\")\n",
    "            for sample_key in sample_keys:\n",
    "                print(f\"    {sample_key} -> {value[sample_key]}\")\n",
    "    else:\n",
    "        print(f\"\\n{key}: {type(value)}\")\n",
    "\n",
    "# Check consistency between datasets and mappings\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"CONSISTENCY CHECK\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if 'user_mapping' in id_mappings:\n",
    "    mapped_users = set(id_mappings['user_mapping'].values())\n",
    "    train_users = set(train_df['user_id'].unique())\n",
    "    test_users = set(test_df['user_id'].unique())\n",
    "    \n",
    "    print(f\"Mapped users: {len(mapped_users)}\")\n",
    "    print(f\"Training users: {len(train_users)}\")\n",
    "    print(f\"Test users: {len(test_users)}\")\n",
    "    print(f\"Overlap train-test: {len(train_users.intersection(test_users))}\")\n",
    "\n",
    "if 'item_mapping' in id_mappings:\n",
    "    mapped_items = set(id_mappings['item_mapping'].values())\n",
    "    train_items = set(train_df['item_id'].unique())\n",
    "    metadata_items = set(item_metadata.index) if 'parent_asin' in item_metadata.columns else set()\n",
    "    \n",
    "    print(f\"Mapped items: {len(mapped_items)}\")\n",
    "    print(f\"Training items: {len(train_items)}\")\n",
    "    print(f\"Metadata items: {len(metadata_items)}\")\n",
    "    print(f\"Items in both train and metadata: {len(train_items.intersection(metadata_items))}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Data Relationships and Correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationships between features\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA RELATIONSHIPS AND CORRELATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Merge training data with item metadata for analysis\n",
    "# First, create a mapping from item_id to metadata index\n",
    "if 'parent_asin' in item_metadata.columns:\n",
    "    # Create reverse item mapping\n",
    "    reverse_item_mapping = {v: k for k, v in id_mappings.get('item_mapping', {}).items()}\n",
    "    \n",
    "    # Add original ASIN to train data\n",
    "    train_df['item_asin'] = train_df['item_id'].map(reverse_item_mapping)\n",
    "    \n",
    "    # Merge with metadata\n",
    "    train_with_metadata = train_df.merge(\n",
    "        item_metadata,\n",
    "        left_on='item_asin',\n",
    "        right_on='parent_asin',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    print(f\"Training data with metadata: {train_with_metadata.shape}\")\n",
    "    print(f\"Successful merges: {train_with_metadata['parent_asin'].notna().sum()}\")\n",
    "\n",
    "# Correlation analysis\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "if len(numeric_cols) > 1:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    correlation_matrix = train_df[numeric_cols].corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Correlation Matrix - Training Data')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Analyze rating patterns by category (if metadata available)\n",
    "if 'main_category' in item_metadata.columns and 'train_with_metadata' in locals():\n",
    "    print(\"\\nRating patterns by category:\")\n",
    "    category_ratings = train_with_metadata.groupby('main_category')['rating'].agg(['mean', 'count', 'std']).round(2)\n",
    "    category_ratings = category_ratings[category_ratings['count'] >= 100]  # Filter categories with enough data\n",
    "    category_ratings = category_ratings.sort_values('mean', ascending=False)\n",
    "    display(category_ratings.head(10))\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    top_categories = category_ratings.head(10)\n",
    "    plt.bar(range(len(top_categories)), top_categories['mean'])\n",
    "    plt.title('Average Rating by Category (Top 10)')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Average Rating')\n",
    "    plt.xticks(range(len(top_categories)), top_categories.index, rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Price vs Rating analysis (if price data available)\n",
    "if 'price_numeric' in item_metadata.columns and 'train_with_metadata' in locals():\n",
    "    price_rating_data = train_with_metadata[['rating', 'price_numeric']].dropna()\n",
    "    if len(price_rating_data) > 0:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(price_rating_data['price_numeric'], price_rating_data['rating'], alpha=0.5)\n",
    "        plt.title('Price vs Rating')\n",
    "        plt.xlabel('Price')\n",
    "        plt.ylabel('Rating')\n",
    "        plt.xscale('log')\n",
    "        \n",
    "        # Add correlation coefficient\n",
    "        corr = price_rating_data['price_numeric'].corr(price_rating_data['rating'])\n",
    "        plt.text(0.05, 0.95, f'Correlation: {corr:.3f}', transform=plt.gca().transAxes)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. Cold Start Problem Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cold start problem analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"COLD START PROBLEM ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analyze new users and items in test set\n",
    "train_users = set(train_df['user_id'].unique())\n",
    "test_users = set(test_df['user_id'].unique())\n",
    "\n",
    "print(\"User cold start analysis:\")\n",
    "print(f\"Total users in training: {len(train_users):,}\")\n",
    "print(f\"Total users in test: {len(test_users):,}\")\n",
    "print(f\"Users appearing in both train and test: {len(train_users.intersection(test_users)):,}\")\n",
    "print(f\"New users in test (cold start): {len(test_users - train_users):,}\")\n",
    "print(f\"Cold start user percentage: {len(test_users - train_users) / len(test_users) * 100:.2f}%\")\n",
    "\n",
    "# Analyze user interaction patterns for cold start mitigation\n",
    "print(\"\\nUser interaction distribution (for warm start strategy):\")\n",
    "user_interaction_counts = train_df['user_id'].value_counts()\n",
    "interaction_stats = user_interaction_counts.describe()\n",
    "display(interaction_stats)\n",
    "\n",
    "# Visualize user interaction distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(user_interaction_counts, bins=50, alpha=0.7)\n",
    "plt.title('Distribution of User Interactions')\n",
    "plt.xlabel('Number of Interactions')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(user_interaction_counts)\n",
    "plt.title('User Interactions Box Plot')\n",
    "plt.ylabel('Number of Interactions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze items that could be recommended to cold start users\n",
    "print(\"\\nPopular items analysis (for cold start recommendations):\")\n",
    "popular_items = train_df.groupby('item_id').agg({\n",
    "    'user_id': 'count',\n",
    "    'rating': ['mean', 'std']\n",
    "}).round(2)\n",
    "popular_items.columns = ['interaction_count', 'avg_rating', 'rating_std']\n",
    "popular_items = popular_items.sort_values('interaction_count', ascending=False)\n",
    "\n",
    "print(\"Top 20 most popular items:\")\n",
    "display(popular_items.head(20))\n",
    "\n",
    "# Analyze seasonal/temporal patterns for recommendations\n",
    "if 'datetime' in train_df.columns:\n",
    "    print(\"\\nTemporal patterns for cold start recommendations:\")\n",
    "    recent_interactions = train_df[train_df['datetime'] >= train_df['datetime'].max() - pd.Timedelta(days=30)]\n",
    "    recent_popular = recent_interactions.groupby('item_id').size().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"Top 10 trending items (last 30 days):\")\n",
    "    display(recent_popular.head(10))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 9. Sparsity Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparsity analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"SPARSITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate sparsity metrics\n",
    "n_users = train_df['user_id'].nunique()\n",
    "n_items = train_df['item_id'].nunique()\n",
    "n_interactions = len(train_df)\n",
    "\n",
    "# Theoretical maximum interactions\n",
    "max_possible_interactions = n_users * n_items\n",
    "sparsity = 1 - (n_interactions / max_possible_interactions)\n",
    "\n",
    "print(f\"Number of users: {n_users:,}\")\n",
    "print(f\"Number of items: {n_items:,}\")\n",
    "print(f\"Number of interactions: {n_interactions:,}\")\n",
    "print(f\"Maximum possible interactions: {max_possible_interactions:,}\")\n",
    "print(f\"Sparsity: {sparsity:.6f} ({sparsity*100:.4f}%)\")\n",
    "print(f\"Density: {1-sparsity:.6f} ({(1-sparsity)*100:.4f}%)\")\n",
    "\n",
    "# Create user-item interaction matrix for visualization\n",
    "print(\"\\nCreating user-item matrix sample...\")\n",
    "# Take a sample for visualization (full matrix would be too large)\n",
    "sample_users = train_df['user_id'].unique()[:100]\n",
    "sample_items = train_df['item_id'].unique()[:100]\n",
    "\n",
    "sample_interactions = train_df[\n",
    "    (train_df['user_id'].isin(sample_users)) & \n",
    "    (train_df['item_id'].isin(sample_items))\n",
    "]\n",
    "\n",
    "# Create pivot table\n",
    "interaction_matrix = sample_interactions.pivot_table(\n",
    "    index='user_id', \n",
    "    columns='item_id', \n",
    "    values='rating',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "print(f\"Sample matrix shape: {interaction_matrix.shape}\")\n",
    "print(f\"Sample matrix sparsity: {(interaction_matrix == 0).sum().sum() / interaction_matrix.size:.4f}\")\n",
    "\n",
    "# Visualize sparsity pattern\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(interaction_matrix.values, cmap='Blues', aspect='auto')\n",
    "plt.title('User-Item Interaction Matrix (Sample 100x100)')\n",
    "plt.xlabel('Items')\n",
    "plt.ylabel('Users')\n",
    "plt.colorbar(label='Rating')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze interaction density by user segments\n",
    "print(\"\\nSparsity by user activity segments:\")\n",
    "user_interaction_counts = train_df.groupby('user_id').size()\n",
    "\n",
    "# Define user segments based on activity\n",
    "percentiles = [0, 50, 90, 95, 99, 100]\n",
    "thresholds = np.percentile(user_interaction_counts, percentiles)\n",
    "\n",
    "for i in range(len(percentiles)-1):\n",
    "    mask = (user_interaction_counts >= thresholds[i]) & (user_interaction_counts < thresholds[i+1])\n",
    "    segment_users = user_interaction_counts[mask].index\n",
    "    segment_data = train_df[train_df['user_id'].isin(segment_users)]\n",
    "    \n",
    "    segment_items = segment_data['item_id'].nunique()\n",
    "    segment_interactions = len(segment_data)\n",
    "    segment_max_interactions = len(segment_users) * segment_items\n",
    "    segment_sparsity = 1 - (segment_interactions / segment_max_interactions) if segment_max_interactions > 0 else 1\n",
    "    \n",
    "    print(f\"  {percentiles[i]:2.0f}-{percentiles[i+1]:2.0f}th percentile: \"\n",
    "          f\"{len(segment_users):,} users, \"\n",
    "          f\"sparsity: {segment_sparsity:.4f}\")\n",
    "\n",
    "# Long tail analysis for items\n",
    "print(\"\\nLong tail analysis:\")\n",
    "item_popularity = train_df['item_id'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Calculate cumulative coverage\n",
    "cumulative_interactions = item_popularity.cumsum()\n",
    "total_interactions = cumulative_interactions.iloc[-1]\n",
    "\n",
    "print(f\"Top 10% of items cover {cumulative_interactions[int(len(item_popularity)*0.1)] / total_interactions * 100:.1f}% of interactions\")\n",
    "print(f\"Top 20% of items cover {cumulative_interactions[int(len(item_popularity)*0.2)] / total_interactions * 100:.1f}% of interactions\")\n",
    "print(f\"Top 50% of items cover {cumulative_interactions[int(len(item_popularity)*0.5)] / total_interactions * 100:.1f}% of interactions\")\n",
    "\n",
    "# Visualize long tail\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(len(item_popularity)), item_popularity.values)\n",
    "plt.title('Item Popularity Distribution (Long Tail)')\n",
    "plt.xlabel('Item Rank')\n",
    "plt.ylabel('Number of Interactions')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "coverage_pct = cumulative_interactions / total_interactions * 100\n",
    "plt.plot(range(len(item_popularity)), coverage_pct.values)\n",
    "plt.title('Cumulative Coverage by Item Rank')\n",
    "plt.xlabel('Item Rank')\n",
    "plt.ylabel('Cumulative Coverage (%)')\n",
    "plt.axhline(y=80, color='r', linestyle='--', label='80% Coverage')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 10. Test Set Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST SET ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "print(f\"Test set columns: {list(test_df.columns)}\")\n",
    "\n",
    "# Analyze test users\n",
    "test_users = set(test_df['user_id'].unique())\n",
    "train_users = set(train_df['user_id'].unique())\n",
    "\n",
    "print(f\"\\nTest user analysis:\")\n",
    "print(f\"Number of test users: {len(test_users):,}\")\n",
    "print(f\"Test users also in training: {len(test_users.intersection(train_users)):,}\")\n",
    "print(f\"New test users (cold start): {len(test_users - train_users):,}\")\n",
    "\n",
    "# For users that exist in training, analyze their behavior\n",
    "existing_test_users = test_users.intersection(train_users)\n",
    "if len(existing_test_users) > 0:\n",
    "    existing_user_data = train_df[train_df['user_id'].isin(existing_test_users)]\n",
    "    \n",
    "    print(f\"\\nExisting test users behavior in training:\")\n",
    "    existing_user_stats = existing_user_data.groupby('user_id').agg({\n",
    "        'item_id': 'count',\n",
    "        'rating': ['mean', 'std']\n",
    "    }).round(2)\n",
    "    existing_user_stats.columns = ['num_interactions', 'avg_rating', 'rating_std']\n",
    "    \n",
    "    print(\"Statistics for existing test users:\")\n",
    "    display(existing_user_stats.describe())\n",
    "    \n",
    "    # Compare with all training users\n",
    "    all_user_stats = train_df.groupby('user_id').agg({\n",
    "        'item_id': 'count',\n",
    "        'rating': ['mean', 'std']\n",
    "    }).round(2)\n",
    "    all_user_stats.columns = ['num_interactions', 'avg_rating', 'rating_std']\n",
    "    \n",
    "    print(f\"\\nComparison with all training users:\")\n",
    "    print(f\"Existing test users - Mean interactions: {existing_user_stats['num_interactions'].mean():.2f}\")\n",
    "    print(f\"All training users - Mean interactions: {all_user_stats['num_interactions'].mean():.2f}\")\n",
    "    print(f\"Existing test users - Mean rating: {existing_user_stats['avg_rating'].mean():.2f}\")\n",
    "    print(f\"All training users - Mean rating: {all_user_stats['avg_rating'].mean():.2f}\")\n",
    "\n",
    "# Analyze submission format\n",
    "print(f\"\\nSample submission analysis:\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")\n",
    "print(f\"Sample submission columns: {list(sample_submission.columns)}\")\n",
    "\n",
    "# Analyze prediction format\n",
    "if 'predictions' in sample_submission.columns:\n",
    "    # Parse predictions to see how many items are recommended per user\n",
    "    sample_predictions = sample_submission['predictions'].iloc[0]\n",
    "    prediction_items = sample_predictions.split()\n",
    "    print(f\"Items per user (sample): {len(prediction_items)}\")\n",
    "    print(f\"Sample predictions: {sample_predictions}\")\n",
    "    \n",
    "    # Check if all predictions have the same format\n",
    "    prediction_lengths = sample_submission['predictions'].apply(lambda x: len(x.split())).value_counts()\n",
    "    print(f\"\\nPrediction lengths distribution:\")\n",
    "    display(prediction_lengths)\n",
    "    \n",
    "    # Analyze what items appear in sample predictions\n",
    "    all_prediction_items = []\n",
    "    for pred in sample_submission['predictions'].head(100):  # Sample to avoid memory issues\n",
    "        all_prediction_items.extend(pred.split())\n",
    "    \n",
    "    prediction_item_counts = pd.Series(all_prediction_items).value_counts()\n",
    "    print(f\"\\nMost recommended items in sample submission:\")\n",
    "    display(prediction_item_counts.head(10))\n",
    "    \n",
    "    # Check if prediction items exist in training\n",
    "    train_items = set(train_df['item_id'].astype(str).unique())\n",
    "    prediction_items_set = set(all_prediction_items)\n",
    "    \n",
    "    print(f\"\\nPrediction items validation:\")\n",
    "    print(f\"Unique items in sample predictions: {len(prediction_items_set)}\")\n",
    "    print(f\"Prediction items also in training: {len(prediction_items_set.intersection(train_items))}\")\n",
    "    print(f\"Prediction items not in training: {len(prediction_items_set - train_items)}\")\n",
    "\n",
    "# Visualize test vs train user overlap\n",
    "plt.figure(figsize=(10, 6))\n",
    "labels = ['Cold Start Users', 'Existing Users']\n",
    "sizes = [len(test_users - train_users), len(test_users.intersection(train_users))]\n",
    "colors = ['lightcoral', 'lightblue']\n",
    "\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Test Set User Distribution')\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 11. Key Insights and Recommendations\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
